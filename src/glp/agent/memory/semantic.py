"""
Semantic Memory Store Implementation.

Provides vector-based semantic memory search using pgvector.
Supports long-term memory storage with tenant isolation.
"""

from __future__ import annotations

import hashlib
import logging
from datetime import datetime
from typing import Any, Optional, Protocol
from uuid import UUID

from ..domain.entities import Memory, MemoryType, UserContext
from ..domain.ports import IMemoryStore

logger = logging.getLogger(__name__)


class IAsyncDBPool(Protocol):
    """Protocol for async database pool."""

    async def acquire(self): ...
    async def execute(self, query: str, *args) -> str: ...
    async def fetch(self, query: str, *args) -> list[Any]: ...
    async def fetchrow(self, query: str, *args) -> Optional[Any]: ...
    async def fetchval(self, query: str, *args) -> Any: ...


class IEmbeddingProvider(Protocol):
    """Protocol for embedding generation."""

    async def embed(self, text: str) -> tuple[list[float], str, int]: ...


class SemanticMemoryStore(IMemoryStore):
    """PostgreSQL + pgvector based semantic memory store.

    Provides:
    - Vector similarity search for memory retrieval
    - Tenant and user isolation
    - Confidence-based ranking
    - Automatic deduplication via content hash
    - Memory lifecycle management

    Usage:
        store = SemanticMemoryStore(db_pool, embedding_provider)

        # Store a memory
        memory = await store.store(Memory(
            tenant_id="tenant-123",
            user_id="user-456",
            memory_type=MemoryType.FACT,
            content="User prefers switches in us-west region",
            confidence=0.9,
        ))

        # Search memories
        results = await store.search(
            query="What region does the user prefer?",
            context=user_context,
            embedding_model="text-embedding-3-large",
            limit=5,
        )
    """

    def __init__(
        self,
        db_pool: IAsyncDBPool,
        embedding_provider: Optional[IEmbeddingProvider] = None,
    ):
        """Initialize the semantic memory store.

        Args:
            db_pool: Async database connection pool
            embedding_provider: Provider for generating embeddings
        """
        self.db = db_pool
        self.embedding_provider = embedding_provider

    async def _set_tenant_context(self, conn, tenant_id: str) -> None:
        """Set the tenant context for RLS policies."""
        await conn.execute(
            "SET LOCAL app.tenant_id = $1",
            tenant_id,
        )

    def _compute_content_hash(self, content: str) -> str:
        """Compute SHA-256 hash of content for deduplication."""
        return hashlib.sha256(content.encode()).hexdigest()

    async def store(self, memory: Memory) -> Memory:
        """Store a new memory with deduplication.

        If a memory with the same content hash exists for this user,
        updates the confidence score instead of creating a duplicate.

        Args:
            memory: Memory to store

        Returns:
            Stored memory (may be updated existing if duplicate)
        """
        # Compute content hash
        content_hash = self._compute_content_hash(memory.content)
        memory.content_hash = content_hash

        # Generate embedding if provider available and not already set
        if self.embedding_provider and not memory.embedding:
            try:
                embedding, model, dimension = await self.embedding_provider.embed(
                    memory.content
                )
                memory.embedding = embedding
                memory.embedding_model = model
                memory.embedding_dimension = dimension
            except Exception as e:
                logger.warning(f"Failed to generate embedding: {e}")
                # Continue without embedding - will be generated by worker

        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, memory.tenant_id)

                # Upsert with conflict handling
                row = await conn.fetchrow(
                    """
                    INSERT INTO agent_memory (
                        id, tenant_id, user_id, memory_type, content, content_hash,
                        embedding, embedding_model, embedding_dimension,
                        source_conversation_id, source_message_id,
                        valid_from, valid_until, confidence, metadata
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
                    ON CONFLICT (tenant_id, user_id, content_hash)
                    DO UPDATE SET
                        confidence = GREATEST(agent_memory.confidence, EXCLUDED.confidence),
                        access_count = agent_memory.access_count + 1,
                        last_accessed_at = NOW(),
                        updated_at = NOW()
                    RETURNING id, created_at, updated_at
                    """,
                    memory.id,
                    memory.tenant_id,
                    memory.user_id,
                    memory.memory_type.value,
                    memory.content,
                    content_hash,
                    memory.embedding,
                    memory.embedding_model,
                    memory.embedding_dimension,
                    memory.source_conversation_id,
                    memory.source_message_id,
                    memory.valid_from,
                    memory.valid_until,
                    memory.confidence,
                    memory.metadata,
                )

                memory.id = row["id"]
                memory.created_at = row["created_at"]
                memory.updated_at = row["updated_at"]

        logger.debug(f"Stored memory {memory.id}: {memory.content[:50]}...")
        return memory

    async def search(
        self,
        query: str,
        context: UserContext,
        embedding_model: str,
        limit: int = 10,
        memory_types: Optional[list[MemoryType]] = None,
        min_confidence: float = 0.0,
    ) -> list[tuple[Memory, float]]:
        """Search memories by semantic similarity.

        Uses pgvector cosine distance for similarity ranking.
        Results are filtered by tenant, user, model, and optionally type.

        Args:
            query: Search query text
            context: User context for tenant isolation
            embedding_model: Model name to filter by (REQUIRED for correct search)
            limit: Maximum results
            memory_types: Filter by memory types
            min_confidence: Minimum confidence threshold

        Returns:
            List of (Memory, distance) tuples sorted by relevance
        """
        if not self.embedding_provider:
            raise ValueError("Embedding provider required for search")

        # Generate query embedding
        query_embedding, _, _ = await self.embedding_provider.embed(query)

        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, context.tenant_id)

                # Build query with optional type filter
                type_filter = ""
                params = [
                    query_embedding,
                    context.user_id,
                    embedding_model,
                    min_confidence,
                    limit,
                ]

                if memory_types:
                    type_values = [t.value for t in memory_types]
                    type_filter = f"AND memory_type = ANY(${len(params) + 1})"
                    params.append(type_values)

                rows = await conn.fetch(
                    f"""
                    SELECT id, tenant_id, user_id, memory_type, content, content_hash,
                           embedding_model, embedding_dimension,
                           access_count, last_accessed_at,
                           source_conversation_id, source_message_id,
                           valid_from, valid_until, confidence, is_invalidated,
                           metadata, created_at, updated_at,
                           embedding <=> $1::vector AS distance
                    FROM agent_memory
                    WHERE user_id = $2
                      AND embedding_model = $3
                      AND confidence >= $4
                      AND NOT is_invalidated
                      AND (valid_until IS NULL OR valid_until > NOW())
                      {type_filter}
                    ORDER BY distance ASC
                    LIMIT $5
                    """,
                    *params,
                )

                results = []
                memory_ids = []
                for row in rows:
                    memory = Memory(
                        id=row["id"],
                        tenant_id=row["tenant_id"],
                        user_id=row["user_id"],
                        memory_type=MemoryType(row["memory_type"]),
                        content=row["content"],
                        content_hash=row["content_hash"],
                        embedding_model=row["embedding_model"],
                        embedding_dimension=row["embedding_dimension"],
                        access_count=row["access_count"],
                        last_accessed_at=row["last_accessed_at"],
                        source_conversation_id=row["source_conversation_id"],
                        source_message_id=row["source_message_id"],
                        valid_from=row["valid_from"],
                        valid_until=row["valid_until"],
                        confidence=row["confidence"],
                        is_invalidated=row["is_invalidated"],
                        metadata=row["metadata"] or {},
                        created_at=row["created_at"],
                        updated_at=row["updated_at"],
                    )
                    results.append((memory, row["distance"]))
                    memory_ids.append(row["id"])

                # Batch update access tracking (single query instead of N queries)
                if memory_ids:
                    await conn.execute(
                        """
                        UPDATE agent_memory
                        SET access_count = access_count + 1,
                            last_accessed_at = NOW()
                        WHERE id = ANY($1)
                        """,
                        memory_ids,
                    )

        logger.debug(f"Found {len(results)} memories for query: {query[:50]}...")
        return results

    async def get(
        self, memory_id: UUID, context: UserContext
    ) -> Optional[Memory]:
        """Get a memory by ID.

        Args:
            memory_id: Memory ID
            context: User context

        Returns:
            Memory if found, None otherwise
        """
        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, context.tenant_id)

                row = await conn.fetchrow(
                    """
                    SELECT id, tenant_id, user_id, memory_type, content, content_hash,
                           embedding_model, embedding_dimension,
                           access_count, last_accessed_at,
                           source_conversation_id, source_message_id,
                           valid_from, valid_until, confidence, is_invalidated,
                           metadata, created_at, updated_at
                    FROM agent_memory
                    WHERE id = $1 AND user_id = $2
                    """,
                    memory_id,
                    context.user_id,
                )

                if not row:
                    return None

                return Memory(
                    id=row["id"],
                    tenant_id=row["tenant_id"],
                    user_id=row["user_id"],
                    memory_type=MemoryType(row["memory_type"]),
                    content=row["content"],
                    content_hash=row["content_hash"],
                    embedding_model=row["embedding_model"],
                    embedding_dimension=row["embedding_dimension"],
                    access_count=row["access_count"],
                    last_accessed_at=row["last_accessed_at"],
                    source_conversation_id=row["source_conversation_id"],
                    source_message_id=row["source_message_id"],
                    valid_from=row["valid_from"],
                    valid_until=row["valid_until"],
                    confidence=row["confidence"],
                    is_invalidated=row["is_invalidated"],
                    metadata=row["metadata"] or {},
                    created_at=row["created_at"],
                    updated_at=row["updated_at"],
                )

    async def update_access(self, memory_id: UUID) -> None:
        """Update access tracking for a memory.

        Increments access count and updates last_accessed_at.

        Args:
            memory_id: Memory ID
        """
        async with self.db.acquire() as conn:
            await conn.execute(
                """
                UPDATE agent_memory
                SET access_count = access_count + 1,
                    last_accessed_at = NOW()
                WHERE id = $1
                """,
                memory_id,
            )

    async def invalidate(self, memory_id: UUID, context: UserContext) -> bool:
        """Soft-delete a memory.

        Args:
            memory_id: Memory ID
            context: User context

        Returns:
            True if invalidated, False if not found
        """
        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, context.tenant_id)

                result = await conn.execute(
                    """
                    UPDATE agent_memory
                    SET is_invalidated = TRUE, updated_at = NOW()
                    WHERE id = $1 AND user_id = $2 AND NOT is_invalidated
                    """,
                    memory_id,
                    context.user_id,
                )

                invalidated = result == "UPDATE 1"

        if invalidated:
            logger.info(f"Invalidated memory {memory_id}")
        return invalidated

    async def get_by_source(
        self,
        conversation_id: Optional[UUID],
        message_id: Optional[UUID],
        context: UserContext,
    ) -> list[Memory]:
        """Get memories extracted from a specific source.

        Args:
            conversation_id: Filter by source conversation
            message_id: Filter by source message
            context: User context

        Returns:
            List of memories from the specified source
        """
        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, context.tenant_id)

                conditions = ["user_id = $1", "NOT is_invalidated"]
                params = [context.user_id]

                if conversation_id:
                    params.append(conversation_id)
                    conditions.append(f"source_conversation_id = ${len(params)}")

                if message_id:
                    params.append(message_id)
                    conditions.append(f"source_message_id = ${len(params)}")

                rows = await conn.fetch(
                    f"""
                    SELECT id, tenant_id, user_id, memory_type, content, content_hash,
                           embedding_model, embedding_dimension,
                           access_count, last_accessed_at,
                           source_conversation_id, source_message_id,
                           valid_from, valid_until, confidence, is_invalidated,
                           metadata, created_at, updated_at
                    FROM agent_memory
                    WHERE {' AND '.join(conditions)}
                    ORDER BY created_at DESC
                    """,
                    *params,
                )

                return [
                    Memory(
                        id=row["id"],
                        tenant_id=row["tenant_id"],
                        user_id=row["user_id"],
                        memory_type=MemoryType(row["memory_type"]),
                        content=row["content"],
                        content_hash=row["content_hash"],
                        embedding_model=row["embedding_model"],
                        embedding_dimension=row["embedding_dimension"],
                        access_count=row["access_count"],
                        last_accessed_at=row["last_accessed_at"],
                        source_conversation_id=row["source_conversation_id"],
                        source_message_id=row["source_message_id"],
                        valid_from=row["valid_from"],
                        valid_until=row["valid_until"],
                        confidence=row["confidence"],
                        is_invalidated=row["is_invalidated"],
                        metadata=row["metadata"] or {},
                        created_at=row["created_at"],
                        updated_at=row["updated_at"],
                    )
                    for row in rows
                ]

    async def cleanup(self, tenant_id: Optional[str] = None) -> dict[str, int]:
        """Run memory lifecycle cleanup.

        Performs:
        1. Invalidate expired memories
        2. Decay confidence for unused memories
        3. Hard delete old invalidated memories

        Args:
            tenant_id: Optional tenant to clean (None = all)

        Returns:
            Dict with counts: invalidated, decayed, deleted
        """
        async with self.db.acquire() as conn:
            if tenant_id:
                await self._set_tenant_context(conn, tenant_id)

            row = await conn.fetchrow(
                "SELECT * FROM agent_memory_cleanup($1)",
                tenant_id,
            )

            result = {
                "invalidated": row["invalidated_count"],
                "decayed": row["decayed_count"],
                "deleted": row["deleted_count"],
            }

        logger.info(f"Memory cleanup: {result}")
        return result

    async def get_stats(self, context: UserContext) -> dict[str, Any]:
        """Get memory statistics for a user.

        Args:
            context: User context

        Returns:
            Statistics dict with counts by type, avg confidence, etc.
        """
        async with self.db.acquire() as conn:
            async with conn.transaction():
                await self._set_tenant_context(conn, context.tenant_id)

                rows = await conn.fetch(
                    """
                    SELECT
                        memory_type,
                        COUNT(*) as count,
                        COUNT(*) FILTER (WHERE NOT is_invalidated) as active_count,
                        AVG(confidence) FILTER (WHERE NOT is_invalidated) as avg_confidence,
                        SUM(access_count) as total_accesses
                    FROM agent_memory
                    WHERE user_id = $1
                    GROUP BY memory_type
                    """,
                    context.user_id,
                )

                stats = {
                    "by_type": {},
                    "total": 0,
                    "active": 0,
                }

                for row in rows:
                    stats["by_type"][row["memory_type"]] = {
                        "count": row["count"],
                        "active": row["active_count"],
                        "avg_confidence": float(row["avg_confidence"]) if row["avg_confidence"] else 0,
                        "total_accesses": row["total_accesses"],
                    }
                    stats["total"] += row["count"]
                    stats["active"] += row["active_count"]

                return stats
